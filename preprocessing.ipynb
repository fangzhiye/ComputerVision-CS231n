{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(\"round1_ijcai_18_train_20180301.csv\", sep=' ')\n",
    " \n",
    "df_test = pd.read_csv(\"round1_ijcai_18_test_a_20180301.csv\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别数量统计\n",
      "instance_id                     478087\n",
      "item_id                         10075\n",
      "item_category_list              14\n",
      "item_property_list              10908\n",
      "item_brand_id                   2055\n",
      "item_city_id                    128\n",
      "item_price_level                14\n",
      "item_sales_level                18\n",
      "item_collected_level            18\n",
      "item_pv_level                   22\n",
      "user_id                         197694\n",
      "user_gender_id                  4\n",
      "user_age_level                  9\n",
      "user_occupation_id              5\n",
      "user_star_level                 12\n",
      "context_id                      478111\n",
      "context_timestamp               281824\n",
      "context_page_id                 20\n",
      "predict_category_property       78796\n",
      "shop_id                         3959\n",
      "shop_review_num_level           25\n",
      "shop_review_positive_rate       11825\n",
      "shop_star_level                 22\n",
      "shop_score_service              16361\n",
      "shop_score_delivery             16423\n",
      "shop_score_description          16463\n",
      "is_trade                        2\n"
     ]
    }
   ],
   "source": [
    "print(\"类别数量统计\")\n",
    "for name in df.head(0):\n",
    "    print(name,\" \"*(30-len(name)),len(df[name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input:\n",
    "sr1: pandas serise\n",
    "sr2: pandas serise\n",
    "return :a list of the intersection of sr1 and sr2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cross_check(sr1,sr2): \n",
    "\n",
    "    a = sr1.unique()\n",
    "    b = sr2.unique()\n",
    "    #print(len(a))\n",
    "    relist = list(set(a).intersection(set(b)))\n",
    "    checkpass = len(relist) == len(a)\n",
    "    return relist,checkpass\n",
    "\n",
    "\n",
    "len(cross_check(df_test[\"item_id\"],df_train[\"item_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值统计\n",
      "item_brand_id                   473\n",
      "item_city_id                    277\n",
      "item_sales_level                913\n",
      "user_gender_id                  12902\n",
      "user_age_level                  964\n",
      "user_occupation_id              964\n",
      "user_star_level                 964\n",
      "shop_review_positive_rate       7\n",
      "shop_score_service              59\n",
      "shop_score_delivery             59\n",
      "shop_score_description          59\n"
     ]
    }
   ],
   "source": [
    "print(\"缺失值统计\")\n",
    "for name in df.head(0):\n",
    "    \n",
    "    if -1 in df[name].value_counts():\n",
    "        print(name,\" \"*(30-len(name)),df[name].value_counts()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature2process = [name for name in df.head(0)]\n",
    "feature2drop = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全部待处理变量\n",
    "```\n",
    "'instance_id',\n",
    " 'item_id',\n",
    " 'item_category_list',\n",
    " 'item_property_list',\n",
    " 'item_brand_id',\n",
    " 'item_city_id',\n",
    " 'item_price_level',\n",
    " 'item_sales_level',\n",
    " 'item_collected_level',\n",
    " 'item_pv_level',\n",
    " 'user_id',\n",
    " 'user_gender_id',\n",
    " 'user_age_level',\n",
    " 'user_occupation_id',\n",
    " 'user_star_level',\n",
    " 'context_id',\n",
    " 'context_timestamp',\n",
    " 'context_page_id',\n",
    " 'predict_category_property',\n",
    " 'shop_id',\n",
    " 'shop_review_num_level',\n",
    " 'shop_review_positive_rate',\n",
    " 'shop_star_level',\n",
    " 'shop_score_service',\n",
    " 'shop_score_delivery',\n",
    " 'shop_score_description',\n",
    " 'is_trade'\n",
    "```\n",
    "\n",
    "## 处理instance变量 ，主要完成去重部分; [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id\n",
      "去重前\n",
      "478138\n",
      "18371\n",
      "去重后\n",
      "478087\n",
      "18371\n"
     ]
    }
   ],
   "source": [
    "print(feature2process[0])\n",
    "print(\"去重前\")\n",
    "print(df_train.count()[0])\n",
    "print(df_test.count()[0])\n",
    "\n",
    "df_train_0 = df_train.drop_duplicates([feature2process[0]])\n",
    "df_test_0 = df_test.drop_duplicates([feature2process[0]])\n",
    "\n",
    "print(\"去重后\")\n",
    "print(df_train_0.count()[0])\n",
    "print(df_test_0.count()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理item_id变量   ;1\n",
    "**对item_id 进行onehot处理，仅保留大于1000的类目，其余都归为other类，并增加count类,对于NaN则全部置零,如无特殊情况之后删除item_id列**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_with_dict(sr,dummy_dict = None,count_dict = None,add_count = True):\n",
    "    if  dummy_dict is None:\n",
    "        dummy_dict = list(sr.unique())\n",
    "    if -1 in dummy_dict:\n",
    "        dummy_dict.remove(-1)\n",
    "    lines = []\n",
    "    line_length = len(dummy_dict) + 1\n",
    "    if add_count and  count_dict is None:\n",
    "        count_dict = sr.value_counts()\n",
    "        count_dict[-1] = 0\n",
    "    for cat_name in sr:\n",
    "        new_line = [0.0] * line_length\n",
    "        if cat_name in dummy_dict:\n",
    "            new_line[dummy_dict.index(cat_name)] = 1\n",
    "        elif cat_name != -1:\n",
    "            new_line[line_length - 1] = 1\n",
    "            \n",
    "        if add_count and cat_name in count_dict:\n",
    "            new_line.append(count_dict[cat_name])\n",
    "        elif add_count :\n",
    "            new_line.append(0)\n",
    "        lines.append(new_line)\n",
    "    header = [str(sr.name)+ '_' +str(cat_name) for cat_name in dummy_dict] \n",
    "    header.append((str(sr.name)+ '_' +\"other\"))\n",
    "    header.append((str(sr.name)+ '_' +\"count\"))\n",
    "    \n",
    "    return pd.DataFrame(np.array(lines),index = sr.index , columns = header),count_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_wrapper(df1,df2,sr1,sr2,dummy_dict = None):\n",
    "    onehot_sr1, count = onehot_with_dict(sr1,dummy_dict=dummy_dict)\n",
    "    onehot_sr2 ,_     = onehot_with_dict(sr2,dummy_dict=dummy_dict, count_dict=count)\n",
    "    return df1.join(onehot_sr1), df2.join(onehot_sr2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3534.000000\n",
      "mean      119.605263\n",
      "std       227.768686\n",
      "min         1.000000\n",
      "25%        14.000000\n",
      "50%        44.000000\n",
      "75%       121.000000\n",
      "max      3001.000000\n",
      "Name: item_id, dtype: float64\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[1]\n",
    "sr_test = df_test_0[this_feature]\n",
    "sr_train = df_train_0[this_feature]\n",
    "common_id,_ = cross_check(sr_test,sr_train)\n",
    "\n",
    "temp = df_train[this_feature].value_counts()[common_id]\n",
    "print(temp.describe())\n",
    "threshold = 1000\n",
    "temp = temp[temp > threshold]\n",
    "print(len(temp))\n",
    "dummy_dict = list(temp.index)\n",
    "#pd.get_dummies(df[feature],prefix = dummy_dict)\n",
    "\"\"\"\n",
    "df_train_p = df_train_p.drop(this_feature, axis = 1)\n",
    "df_test_p = df_test_p.drop(this_feature, axis = 1)\n",
    "\"\"\"\n",
    "feature2drop.append(this_feature)\n",
    "\n",
    "df_train_1, df_test_1 = onehot_wrapper(df_train_0,df_test_0,sr_train,sr_test,dummy_dict = dummy_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478087, 74)\n",
      "(18371, 73)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_1.shape)\n",
    "print(df_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理item_category_list ;2\n",
    "\n",
    "可以看出所有商品的cat0是相同的，可以直接抛弃\n",
    "\n",
    "只有子类目不同只需要对子类目进行one-hot\n",
    "\n",
    "所有商品都有cat1，直接进行one_hot编码\n",
    "\n",
    "部分商品有cat2，有cat2的正常进行one_hot编码，对于没有的置为（0，0）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sub_cat(sr):\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    i = 0\n",
    "    for cat in sr:\n",
    "        a.append(cat.split(';')[0])\n",
    "        b.append(cat.split(';')[1])\n",
    "        if len(cat.split(';')) != 2:\n",
    "            c.append(cat.split(';')[2])\n",
    "        else:\n",
    "            c.append(None)\n",
    "        #print(i,cat) \n",
    "        #i += 1\n",
    "    cat0 = pd.Series(a,index = sr.index)\n",
    "    cat1 = pd.Series(b,index = sr.index)\n",
    "    cat2 = pd.Series(c,index = sr.index)\n",
    "    return cat0, cat1, cat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "(478087, 89)\n",
      "(18371, 88)\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[2]\n",
    "sr_test = df_test_1[this_feature]\n",
    "sr_train = df_train_1[this_feature]\n",
    "\n",
    "_, cat_train1, cat_train2 = get_sub_cat(sr_train)\n",
    "_, cat_test1, cat_test2 = get_sub_cat(sr_test)\n",
    "print(cross_check(cat_train1,cat_test1)[1])\n",
    "print(cross_check(cat_train2,cat_test2)[1])\n",
    "\n",
    "df_train_2 = df_train_1.join(pd.get_dummies(cat_train1,prefix = 'item_cat1' ).astype('float'))\n",
    "df_train_2 = df_train_2.join(pd.get_dummies(cat_train2,prefix = 'item_cat2' ).astype('float'))\n",
    "\n",
    "df_test_2 = df_test_1.join(pd.get_dummies(cat_train1,prefix = 'item_cat1' ).astype('float'))\n",
    "df_test_2 = df_test_2.join(pd.get_dummies(cat_train2,prefix = 'item_cat2' ).astype('float'))\n",
    "\n",
    "\n",
    "feature2drop.append(this_feature)\n",
    "\n",
    "#pd.get_dummies(cat_train2).astype('float')\n",
    "#cat_train2\n",
    "print(df_train_2.shape)\n",
    "print(df_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_property_list；3\n",
    "\n",
    "经过测试所有的每个纪录之间的property数量相差很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "this_feature = feature2process[3]\n",
    "sr_test = df_test_2[this_feature]\n",
    "sr_train = df_train_2[this_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 82, 85, 88, 89, 91, 93, 97, 99, 100}\n",
      "{7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 74, 75, 76, 77, 82, 85, 88, 89, 91, 97, 99, 100}\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for cat in sr_train:\n",
    "    length.append(len(cat.split(';')))\n",
    "print(set(length))\n",
    "\n",
    "length = []\n",
    "for cat in sr_test:\n",
    "    length.append(len(cat.split(';')))\n",
    "print(set(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_property_dict(sr):\n",
    "    property_dict = {}\n",
    "    for cat in sr:\n",
    "        for item_property in cat.split(';'):\n",
    "            if item_property not in property_dict:\n",
    "                property_dict[item_property] = 1\n",
    "            else:\n",
    "                property_dict[item_property] += 1\n",
    "    return property_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61407\n",
      "26261\n"
     ]
    }
   ],
   "source": [
    "print(len(get_property_dict(sr_train)))\n",
    "print(len(get_property_dict(sr_test)))\n",
    "df_test_3 = df_test_2 \n",
    "df_train_3 = df_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_brand_id；4\n",
    "\n",
    "与item_id 类似，仅保留大于2000的类目，其余都归为other类，并增加count类,对于NaN则全部置零,如无特殊情况之后删除item_id列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_brand_id\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[4]\n",
    "print(this_feature)\n",
    "sr_test = df_test_3[this_feature]\n",
    "sr_train = df_train_3[this_feature]\n",
    "common_id,_ = cross_check(sr_test,sr_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1081.000000\n",
      "mean       431.760407\n",
      "std       2290.940261\n",
      "min          1.000000\n",
      "25%         29.000000\n",
      "50%        106.000000\n",
      "75%        343.000000\n",
      "max      69746.000000\n",
      "Name: item_brand_id, dtype: float64\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "temp = df_train[this_feature].value_counts()[common_id]\n",
    "print(temp.describe())\n",
    "threshold = 2000\n",
    "temp = temp[temp > threshold]\n",
    "print(len(temp))\n",
    "dummy_dict = list(temp.index)\n",
    "\n",
    "feature2drop.append(this_feature)\n",
    "\n",
    "df_train_4, df_test_4 = onehot_wrapper(df_train_3,df_test_3,sr_train,sr_test,dummy_dict = dummy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_city_id；5\n",
    "\n",
    "与item_id 类似，仅保留大于2000的类目，其余都归为other类，并增加count类,对于NaN则全部置零,如无特殊情况之后删除item_id列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_city_id\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[5]\n",
    "print(this_feature)\n",
    "sr_test = df_test_4[this_feature]\n",
    "sr_train = df_train_4[this_feature]\n",
    "common_id,b = cross_check(sr_test,sr_train)\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count        99.000000\n",
      "mean       4825.222222\n",
      "std       18039.425273\n",
      "min           2.000000\n",
      "25%          88.500000\n",
      "50%         277.000000\n",
      "75%        1466.500000\n",
      "max      154991.000000\n",
      "Name: item_city_id, dtype: float64\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "temp = df_train[this_feature].value_counts()[common_id]\n",
    "print(temp.describe())\n",
    "threshold = 10000\n",
    "temp = temp[temp > threshold]\n",
    "print(len(temp))\n",
    "\n",
    "dummy_dict = list(temp.index)\n",
    "\n",
    "feature2drop.append(this_feature)\n",
    "\n",
    "df_train_5, df_test_5 = onehot_wrapper(df_train_4,df_test_4,sr_train,sr_test,dummy_dict = dummy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_price_level ；6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_sales_level ；7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_collected_level ；8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理item_pv_level；9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_id；10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsr= pd.Series([1,2,4,1,2,-1,-1,2,4,0,10])\\na,count = cat2count(sr)\\nprint(a)\\nsr= pd.Series([1,2,1,2,8,5,9,2,4,0,-1,-1])\\nb,_ = cat2count(sr,count)\\nprint(b)\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " 把一个sr依照count_dict变为计数编码，如果不在countdict中或者为缺失值，则置0\n",
    "\"\"\"\n",
    "\n",
    "def cat2count(sr,count_dict = None):\n",
    "    sr.value_counts()\n",
    "    lines = []\n",
    "    if count_dict is None:\n",
    "        count_dict = sr.value_counts()\n",
    "        count_dict[-1] = 0\n",
    "    for cat_name in sr:\n",
    "        if cat_name in count_dict:\n",
    "            new_line = [count_dict[cat_name]]\n",
    "        else:\n",
    "            new_line = [0]\n",
    "        lines.append(new_line)\n",
    "    header = [(str(sr.name)+ '_' +\"count\")]\n",
    "    return pd.DataFrame(np.array(lines),index = sr.index , columns = header) ,count_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sr= pd.Series([1,2,4,1,2,-1,-1,2,4,0,10])\n",
    "a,count = cat2count(sr)\n",
    "print(a)\n",
    "sr= pd.Series([1,2,1,2,8,5,9,2,4,0,-1,-1])\n",
    "b,_ = cat2count(sr,count)\n",
    "print(b)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "此处均为按照train集的计数来进行变换。\n",
    "\"\"\"\n",
    "\n",
    "def count_wrapper(df1,df2,sr1,sr2):\n",
    "    a,count = cat2count(sr1)\n",
    "    b,_ = cat2count(sr2,count_dict=count)\n",
    "    return df1.join(a),df2.join(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[10]\n",
    "print(this_feature)\n",
    "sr_test = df_test_5[this_feature]\n",
    "sr_train = df_train_5[this_feature]\n",
    "common_id,b = cross_check(sr_test,sr_train)\n",
    "print(b)\n",
    "\n",
    "feature2drop.append(this_feature)\n",
    "\n",
    "df_train_10, df_test_10 = count_wrapper(df_train_5,df_test_5,sr_train,sr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3626"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3626.000000\n",
       "mean        1.426641\n",
       "std         0.879653\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        14.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_test.value_counts()[common_id].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3626.000000\n",
       "mean        3.736624\n",
       "std         4.132611\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         5.000000\n",
       "max        56.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_train.value_counts()[common_id].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8778.000000\n",
       "mean        1.024607\n",
       "std         0.160708\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         4.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交易成功次数最多的id都只有四次\n",
    "temp = df_train.is_trade\n",
    "sr_train[temp == 1].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_gender_id；11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_gender_id\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[11]\n",
    "print(this_feature)\n",
    "sr_test = df_test_10[this_feature]\n",
    "sr_train = df_train_10[this_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_11 = df_train_10.join(pd.get_dummies(sr_train,prefix = 'user_gender_id' ).astype('float'))\n",
    "df_test_11 = df_test_10.join(pd.get_dummies(sr_test,prefix = 'user_gender_id' ).astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_age_level；12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_occupation_id ；13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_occupation_id\n"
     ]
    }
   ],
   "source": [
    "this_feature = feature2process[13]\n",
    "print(this_feature)\n",
    "sr_test = df_test_11[this_feature]\n",
    "sr_train = df_train_11[this_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_13 = df_train_11.join(pd.get_dummies(sr_train,prefix = 'user_occupation_id' ).astype('float'))\n",
    "df_test_13 = df_test_11.join(pd.get_dummies(sr_test,prefix = 'user_occupation_id' ).astype('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理user_star_level； 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
